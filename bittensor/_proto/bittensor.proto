// python3 -m grpc.tools.protoc bittensor/_proto/bittensor.proto  -I. --python_out=. --grpc_python_out=. --proto_path bittensor/_proto/
syntax = "proto3";

service TextLastHiddenState {
	rpc Forward (ForwardTextLastHiddenStateRequest) returns (ForwardTextLastHiddenStateResponse) {}
	rpc Backward (BackwardTextLastHiddenStateRequest) returns (BackwardTextLastHiddenStateResponse) {}
}

service TextCausalLMNext {
	rpc Forward (ForwardTextCausalLMNextRequest) returns (ForwardTextCausalLMNextResponse) {}
	rpc Backward (BackwardTextCausalLMNextRequest) returns (BackwardTextCausalLMNextResponse) {}
}

service TextSeq2Seq  {
	rpc Forward (ForwardTextSeq2SeqRequest) returns (ForwardTextSeq2SeqResponse) {}
}
 
/////////////////
// TextSeq2Seq //
/////////////////
// Forward Request.
message ForwardTextSeq2SeqRequest {
    // Caller information.
    int32 version = 1;
	string hotkey = 2;	

    // Serializers required on forward messages.
	Serializer text_prompt_serializer_type = 3;
	Serializer generations_serializer_type = 4;

    // Tokenized text response.
	Tensor serialized_text_prompt = 5;

    // Specifies the number of Topk logits to return.
    // Logit values are packed (pos, value) acocording 
    // to the bittensor tokenizer vocab size.
    int32 topk = 6;

    // Number of tokens to predict
    int32 num_to_generate = 7;

    //Generate Arguments
    // Number of beams
    int32 num_beams = 8;

    //Number of repeat words
    int32 no_repeat_ngram_size = 9;

    //Early Stopping
    bool early_stopping = 10;
    
    //Number of return seuqences
    int32 num_return_sequences = 11;

    //If sampling should be used
    bool do_sample = 12;

    //The probability cutoff
    float top_p = 13;

    //temperature of the softmax function
    float temperature = 15;

    //penalty for repeated words
    float repetition_penalty = 16; 

    //penalty for length 
    float length_penalty = 17;

    //maximum amount of time 
    float max_time = 18;

    //groups for beam search
    int32 num_beam_groups = 19;

	// QueryTimeout
	float timeout = 20;
}

// Forward Response.
message ForwardTextSeq2SeqResponse {
    int32 version = 1;
	string hotkey = 2;	

    // Logits containing generated text.
	Tensor serialized_generations = 3;

	string message = 4;
	ReturnCode return_code = 5; 
}

/////////////////////////
// TextLastHiddenState //
/////////////////////////
message ForwardTextLastHiddenStateRequest {
	int32 version = 1;
	string hotkey = 2;	

	Serializer mask_serializer_type = 3;
	Serializer text_inputs_serializer_type = 4;
	Serializer hidden_states_serializer_type = 5;

	Tensor serialized_text_inputs = 6;
	Tensor serialized_mask = 7;

	// QueryTimeout
	float timeout = 8;
}

message ForwardTextLastHiddenStateResponse {
	int32 version = 1;
	string hotkey = 2;	

	Tensor serialized_hidden_states = 3;

	string message = 4;
	ReturnCode return_code = 5; 
}

message BackwardTextLastHiddenStateRequest {
	int32 version = 1;
	string hotkey = 2;	

	Serializer mask_serializer_type = 3;
	Serializer hidden_states_serializer_type = 4;
	Serializer hidden_states_grads_serializer_type = 5;
	Serializer text_inputs_serializer_type = 6;

	Tensor serialized_text_inputs = 7;
	Tensor serialized_hidden_states = 8;
	Tensor serialized_hidden_states_grads = 9;
	Tensor serialized_mask = 10;
}

message BackwardTextLastHiddenStateResponse {
	int32 version = 1;
	string hotkey = 2;	
	string message = 3;
	ReturnCode return_code = 4; 
}

/////////////////////////
// TextCausalLMNext //
/////////////////////////
message ForwardTextCausalLMNextRequest {
	int32 version = 1;
	string hotkey = 2;

	Serializer mask_serializer_type = 3;
	Serializer text_inputs_serializer_type = 4;
	Serializer hidden_states_serializer_type = 5;

	Tensor serialized_text_inputs = 6;
	Tensor serialized_mask = 7;

	// QueryTimeout
	float timeout = 8;
}

message ForwardTextCausalLMNextResponse {
	int32 version = 1;
	string hotkey = 2;

	Tensor serialized_hidden_states = 3;

	string message = 4;
	ReturnCode return_code = 5;
}

message BackwardTextCausalLMNextRequest {
	int32 version = 1;
	string hotkey = 2;

	Serializer mask_serializer_type = 3;
	Serializer hidden_states_serializer_type = 4;
	Serializer hidden_states_grads_serializer_type = 5;
	Serializer text_inputs_serializer_type = 6;

	Tensor serialized_text_inputs = 7;
	Tensor serialized_hidden_states = 8;
	Tensor serialized_hidden_states_grads = 9;
	Tensor serialized_mask = 10;
}

message BackwardTextCausalLMNextResponse {
	int32 version = 1;
	string hotkey = 2;
	string message = 3;
	ReturnCode return_code = 4;
}

/////////////////////////
// TextCausalLM //
/////////////////////////
message ForwardTextCausalLMRequest {
	int32 version = 1;
	string hotkey = 2;	

	Serializer input_text_serializer = 3;
	Serializer output_logits_serializer = 4;

	Tensor input_text = 5;

	// Specifies the number of Topk logits to return.
	// Logit values are packed (pos, value) acocording 
	// to the bittensor tokenizer vocab size.
	int32 topk = 6;

	// QueryTimeout
	float timeout = 7;
}

message ForwardTextCausalLMResponse {
	int32 version = 1;
	string hotkey = 2;	
	
	Tensor output_logits = 3;

	// Specifies the number of Topk logits to return.
	// Logit values are packed (pos, value) acocording 
	// to the bittensor tokenizer vocab size.
	int32 topk = 4;

	string message = 5;
	ReturnCode return_code = 6; 
}


// Return codes from Backward and Forward call.
enum ReturnCode {
	NoReturn = 0; // Default Value
	Success = 1; // Succesfull query.
	Timeout = 2; // Request timeout.
	Backoff = 3; // Call triggered a backoff.
	Unavailable = 4; // Endpoint not available.
	NotImplemented = 5; // Modality not implemented.
	EmptyRequest = 6; // Request is empty.
	EmptyResponse = 7; // Response is empty.
	InvalidResponse = 8; // Request is invalid.
	InvalidRequest = 9; // Response is invalid.
	RequestShapeException = 10; // Request has invalid shape.
	ResponseShapeException = 11; // Response has invalid shape.
	RequestSerializationException = 12; // Request failed to serialize.
	ResponseSerializationException = 13; // Response failed to serialize.
	RequestDeserializationException = 14; // Request failed to deserialize.
	ResponseDeserializationException = 15; // Response failed to deserialize.
	NotServingNucleus = 16; // Receiving Neuron is not serving a Nucleus to query.
	NucleusTimeout = 17; // Processing on the server side timeout.
	NucleusFull = 18; // Returned when the processing queue on the server is full.
	RequestIncompatibleVersion = 19; // The request handler is incompatible with the request version.
	ResponseIncompatibleVersion = 20; // The request handler is incompatible with the request version.
	SenderUnknown = 21; // The requester is not known by the reciever. 
	UnknownException = 22; // Unknown exception.
	Unauthenticated = 23; // Authentication failed.
	BadEndpoint = 24; // Dummy endpoint
}

/////////////////
// TensorProto //
/////////////////
// A serialized tensor object created using the serializer class.
// SIZE: 32 bytes + variable buffer size.
message Tensor {
	// Version: [REQUIRED] Strictly increasing protocol version identifier.
	// Indentifies protocol version for backward compatibility.
	// i.e. '0.1.5' = (100 * 0) + (10 * 1) + (1 * 5) = 15
	int32 version = 1;

	// Buffer: [REQUIRED] Serialized raw tensor content.
	bytes buffer = 2;

	// Shape: [REQUIRED] Shape of this tensor.
	// NOTE: Variable dimensions (i.e. batch) are non-explicit here as -1.
	// ~ 5 * int32 = 128 bits - (16 bytes)
	repeated int64 shape = 3;

	// Serializer: [REQUIRED] Specifies the serialization/deserialization method.
	// Users should be able to decode all tensors by specifying the encoding type and the raw data. 
	// i.e.
	// 1. (client) serializer = bittensor.bittensor.serializer_for_type(bittensor.Serializer.MSGPACK)
	// 2. (client) serializer.serialize(torch.Tensor, from_type = bittensor.proto.TensorType.TORCH) --> bittensor.proto.Tensor
	// 3. (server) deserializer = bittensor.bittensor.serializer_for_type(request.serialzer)
	// 4. (server) deserializer.deserialize(request.tensor, to_type = bittensor.proto.TensorType.TENSORFLOW) --> tensorflow.Tensor    	
	// SIZE: 32-bits (4 bytes)
	Serializer serializer = 4;

	// TensorType: [REQUIRED] Purely a placeholder, not used in deserialization etc, 
	// however, could come in handy later
	// SIZE: 32-bits (4 bytes)
	TensorType tensor_type = 5;
    	
	// Dtype: [REQUIRED] The tensor datatype.
	// Used for serialization deserialization.
	// int32 32-bits (4-bytes)
	DataType dtype = 6;

	// Requires grad: [OPTIONAL] Does this tensor require a gradient.
	// 1 bit.
	bool requires_grad = 8;
}


enum Serializer {
	// PICKLE = 0; // PICKLE serializer (REMOVED for security reasons.)
	MSGPACK = 0; // MSGPACK serializer
	CMPPACK = 1; // CMPPACK serializer
}

// TensorType: [REQUIRED] The tensor type, for use between multipl frameworks.
enum TensorType {
	TORCH = 0; // Torch object
	TENSORFLOW = 1; // Tensorflow tensor type.
	NUMPY = 2; // Numpy tensor type.
}

// Dtype: [REQUIRED] The tensor datatype.
// Used for serialization deserialization.
// int32 32-bits (4-bytes)
enum DataType {
	UNKNOWN = 0;
	FLOAT32 = 1;
	FLOAT64 = 2;
	INT32 = 3;
	INT64 = 4;
	UTF8 = 5;
	FLOAT16 = 6;
	BOOL = 7;
}



